<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Deformable Neural Radiance Fields creates free-viewpoint portraits (nerfies) from casually captured videos.">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>BO-QSA: Unsupervised Object-Centric Learning with Bi-Level Optimized Query Slot Attention</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<!-- <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://yuliu.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div>
</nav> -->


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title has-text-centered" style="margin-bottom: 0.5em">
            BO-QSA: Unsupervised Object-Centric Learning with Bi-Level Optimized Query Slot Attention
          </h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://buzz-beater.github.io">Baoxiong Jia✶</a><sup>1,3</sup>,</span>
            <span class="author-block">
              <a href="https://yuliu.com">Yu Liu✶</a><sup>2,3</sup>,</span>
            <span class="author-block">
              <a href="https://siyuanhuang.com">Siyuan Huang</a><sup>3</sup>,
            </span>
          </div>

          <p style="font-size: 0.9em; padding: 0.5em 0;">✶ indicates equal contribution</p>

          <p style="font-size: 1em;">
            <sup>1</sup>UCLA<br>
            <sup>2</sup>Tsinghua University<br>
            <sup>3</sup>Beijing Institute for General Artificial Intelligence (BIGAI)<br>
          </p>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2210.08990.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2210.08990"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/YuLiu-LY/BO-QSA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a> -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<div class="has-text-centered" style="padding: 0 1em;">
  <img src="./static/images/overview.png" width="1000">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="content has-text-justified">
          <p>
            We proposed methods for (1) initializing Slot-Attention modules with learnable queries and (2) optimizing 
            the model with bi-level optimization. With simple code adjustments on the 
            vanilla Slot-Attention, our model, Bi-level Optimized Query Slot Attention, 
            achieves state-of-the-art results on 3 challenging synthetic and 7 complex real-world datasets in 
            unsupervised image segmentation and reconstruction, outperforming previous baselines by a large margin.
          </p>
        </div>
      </div>
    </div>
  </div>
</div>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            The ability to decompose complex natural scenes into meaningful object-centric abstractions 
            lies at the core of human perception and reasoning. In the recent culmina- tion of 
            unsupervised object-centric learning, the Slot-Attention module has played an important 
            role with its simple yet effective design and fostered many powerful variants. 
            These methods, however, have been exceedingly difficult to train without supervision and 
            are ambiguous in the notion of object, especially for complex natu- ral scenes. In this paper, 
            we propose to address these issues by improving previous attempts that leverage bi-level optimization 
            in Slot-Attention with learnable query initializations and straight-through gradient updates. 
            With simple code adjustments on Slot-Attention, our model, Bi-level Optimized Query Slot Attention, 
            achieves state-of-the-art results on 3 challenging synthetic and 7 complex real-world datasets in 
            unsupervised image segmentation and reconstruction, outperforming previous baselines by a large margin. 
            We provide thorough ablative studies to validate the necessity and effectiveness of our design. 
            Additionally, our model exhibits great potential for concept binding and zero-shot learning. 
            We hope our effort could provide a single home for the design and learning of slot-based models and 
            pave the way for more challenging tasks in object-centric learning. Our work is made publicly available 
            at: https://bo-qsa.github.io
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div>
    <!--/ Paper video. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Results. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <!-- Quantitative Results. -->
        <hr>
        <div id="results" class="content-block">
          <h2 class="sub-title has-text-centered">Quantitative Results</h2>
          <div class="content has-text-justified">
            <p>
              We demonstrate results on 3 challenging synthetic and 7 complex real-world datasets.
            </p>
          </div>
          <div class="task">
            <div class="columns is-centered" style="position: relative;">
              <div class="control" style="position: absolute; left: 3%;">
                <label class="radio">
                  <input value="MPH1Library" type="radio" name="scene"> MPH1Library
                </label>
                <br>
                <label class="radio">
                  <input value="MPH16" type="radio" name="scene"> MPH16
                </label>
                <br>
                <label class="radio">
                  <input value="N0SittingBooth" type="radio" name="scene"> N0SittingBooth
                </label>
                <br>
                <label class="radio">
                  <input value="N3OpenArea" type="radio" name="scene"> N3OpenArea
                </label>
              </div>
              <div id="pose_loading" style="position: absolute; left: 50%; top: 45%;"></div>
              <canvas id="webgl_pose" style="height: 50%; width: 50%;"></canvas>
            </div>
            <p style="margin: 0 1.5em; font-size: 0.8em; text-align:justify;">Note: Click the radio button to select a scene for result visualization and drag to move your view around.</p>
          </div>
        </div>

        <hr>
        <br/>
        <!--/ Quantitative Results. -->

        <!-- Qualitative Results. -->
        <h2 class="title is-4">Qualitative Results</h2>
        <section class="hero is-dark is-small">
          <div class="hero-body">
            <div class="container has-text-centered">
              <div id="results-carousel" class="carousel results-carousel">

                <div>
                  <div class="results-item">
                    <img src="./static/images/main_results.png" alt="main_results">
                  </div>
                </div>
        
                <div>
                  <div class="results-item">
                    <img src="./static/images/bind_transfer.png" alt="bind_transfer">
                  </div>
                </div>
        
                <div>
                  <div class="results-item">
                    <img src="./static/images/clevrtex.png" alt="clevrtex">
                  </div>
                </div>
        
                <div>
                  <div class="results-item">
                    <img src="./static/images/PTR1.png" alt="PTR1">
                  </div>
                </div>
        
                <div>
                  <div class="results-item">
                    <img src="./static/images/shapestacks.png" alt="shapestacks">
                  </div>
                </div>
        
              </div>
        
              <div class="columns is-centered has-text-centered">
                <div class="column is-three-quarters">
                  <p>
                    Here we show results generated with <i>HyperNeRF</i>. These videos show the input video
                    being
                    played
                    back with a stabilized novel camera path. The right side video shows the depth of the
                    scene.
                    Click on the arrows or drag to see more results.
                  </p>
                </div>
              </div>
            </div>
          </div>
        </section>
        <!--/ Qualitative Results. -->

      </div>
    </div>
    <!--/ Results. -->

  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{jia2022egotaskqa,
      title = {Unsupervised Object-Centric Learning with Bi-Level Optimized Query Slot Attention},
      author = {Jia, Baoxiong and Liu, Yu and Huang, Siyuan},
      journal = {arXiv preprint arXiv:2210.08990},
      year = {2022}
  }</code></pre>
  </div>
</section>



</body>
</html>
